Basic Exploration: A quick data exploration of a fictitious dvd rental store.

SELECT 
* FROM 
dvd_rentals.language;
– Select is very key in exploring data.

SELECT 
* FROM 
dvd_rentals.rental LIMIT 10;
– Limit is a keyword used to restrict query results.

SELECT
country
FROM dvd_rentals.country
ORDER BY country LIMIT 10;
– Order by is used to return an explicitly ordered output.

SELECT 
country 
FROM dvd_rentals.country 
ORDER BY 1 DESC 
LIMIT 10;
–Sorting for any column with numbers, dates, timestamps is done from lowest to highest or latest to earliest for date time related columns.

Practice Questions
1. What is the name of the category with the highest category_id in the dvd_rentals.category table?
SELECT 
name, category_id 
FROM dvd_rentals.category
ORDER BY category_id DESC 
LIMIT 5;

2. For the films with the longest length, what is the title of the “R” rated film with the lowest replacement_cost in dvd_rentals.film table?
SELECT
title, length, rating, replacement_cost 
FROM dvd_rentals.film 
ORDER BY length desc, replacement_cost;

3. Who was the manager of the store with the highest total_sales in the dvd_rentals.sales_by_store table?
SELECT 
manager, total_sales 
FROM dvd_rentals.sales_by_store 
ORDER BY total_sales desc;

4.What is the postal_code of the city with the 5th highest city_id in the dvd_rentals.address table?
SELECT postal_code, city_id 
FROM dvd_rentals.address 
ORDER BY city_id desc 
LIMIT 6;

  
  Some more exploratory functions:
SELECT 
COUNT(*) as row_total 
FROM dvd_rentals.film_list;
– Count returns the number of rows in a dataset. This is important to know as data size has an effect on performance.
–As is an alias which is used to specify a name for an expression in the select statement.

SELECT 
DISTINCT rating 
FROM dvd_rentals.film_list;
–Distinct is a keyword to obtain unique values from a target column.

SELECT 
COUNT(DISTINCT rating) as unique_rating_count 
FROM dvd_rentals.film_list;
– Count function with the distinct keyword finds the number of unique values of a specific column.

SELECT 
rating, COUNT(rating) as frequency 
FROM dvd_rentals.film_list 
GROUP BY rating;
–Group by is a keyword used to divide data into different groups based off the values of selected columns.

SELECT 
rating, category, 
COUNT(rating) as frequency,
ROUND(100 * COUNT(*) / SUM(COUNT(*)) OVER(), 2) as percentage 
FROM dvd_rentals.film_list 
GROUP BY rating, category 
ORDER BY frequency DESC 
LIMIT 5;
–Group by keyword can take on additional columns in the grouping expressions at the bottom of the SQL statement.

Practice Questions
1. Which actor_id has the most number of unique film_id records in the dvd_rentals.film_actor table?
SELECT 
actor_id, 
COUNT(DISTINCT film_id) as film_id_count 
FROM dvd_rentals.film_actor 
GROUP BY actor_id 
ORDER BY film_id_count 
DESC LIMIT 5;

2. How many distinct fid values are there for the 3rd most common price value in the dvd_rentals.nicer_but_slower_film_list table?
SELECT 
price, COUNT(DISTINCT fid) as fid_count 
FROM dvd_rentals.nicer_but_slower_film_list 
GROUP BY price 
ORDER BY fid_count 
DESC LIMIT 5;

3. How many unique country_id values exist in the dvd_rentals.city table?
SELECT 
COUNT(DISTINCT country_id) 
FROM dvd_rentals.city;

4. What percentage of overall total_sales does the Sports category make up in the dvd_rentals.sales_by_film_category table?
SELECT 
category, 
ROUND(100 * total_sales / SUM(total_sales) OVER(), 2) as percentage 
FROM dvd_rentals.sales_by_film_category;

5. What percentage of unique fid values are in the Children category in the dvd_rentals.film_list table?
SELECT 
category, 
ROUND(100 * COUNT(*) / SUM(COUNT(*)) OVER(), 2) as percentage 
FROM dvd_rentals.film_list 
GROUP BY category;
ORDER BY city_id DESC
 LIMIT 6;

  Data Cleaning
SELECT 
measure, 
COUNT(*) as frequency, 
ROUND(100 * COUNT(*) / SUM (COUNT(*)) OVER (), 2) as percentage 
FROM health.user_logs 
GROUP BY measure 
ORDER BY frequency DESC;
– Group by and Order by DESC are very useful in identifying the number of occurrence of values. Here, the number and percentage of duplicate values were identified

SELECT 
id, 
COUNT(*) as frequency, 
ROUND(100 * COUNT(*) / SUM (COUNT(*)) OVER (), 2) as percentage 
FROM health.user_logs 
GROUP BY id 
ORDER BY frequency DESC;
–The number of occurrence of ids was found and those with an occurrence greater than one have duplicates

SELECT 
measure_value,
COUNT(*) as frequency FROM health.user_logs 
GROUP BY measure_value 
ORDER BY frequency DESC;
–This shows the number of occurrence of each measure_value

SELECT 
measure, 
count(*) FROM health.user_logs 
WHERE measure_value = 0 
GROUP BY measure;
–Further exploration showed that most of the measure_value was 0 when selected measure was ‘blood_pressure’.

SELECT
* FROM health.user_logs 
WHERE measure_value = 0 
AND measure = 'blood_pressure';
–This results of this code solidifies the suspicions we had about the measure_value being 0 when selected measure was ‘blood_pressure’.

Ways of identifying duplicates

1. Use of subquery: A subquery is a query that appears inside another query statement. Subqueries are also referred to as sub- SELECT sor nested SELECT.
SELECT 
COUNT(*) 
FROM 
( SELECT 
DISTINCT * 
FROM health.user_logs 
) as subquery;
–An alias is important when writing a subquery.

2. CTE stands for Common Table Expression. A CTE is a SQL query that manipulates existing data and stores the data outputs as a new reference, 
very similar to storing data in a new temporary Excel sheet. it can be referenced with a SELECT, INSERT, UPDATE, or DELETE statement.

WITH logs as
( SELECT 
DISTINCT * FROM health.user_logs 
)
SELECT 
COUNT(*) 
FROM logs;
– logs in this case is the name of the common table expression.

3. Temporary tables is one way of identifying duplicates , it is used best only the deduplicated data will be further analyzed.
The main benefit of using temporary tables is removing the need to always run the same DISTINCT command every time you want to run a query on the deduplicated records.

CREATE TEMP TABLE cleaned_health_logs as 
SELECT 
DISTINCT * 
FROM health.user_logs;
–This will not return an output

SELECT 
* FROM cleaned_health_logs;
–This returns your distinct user logs in the deduplicated temporary table

Danny’s recommended method and my personal best.
SELECT 
id, 
log_date,
measure, 
measure_value, 
systolic, 
diastolic, 
COUNT(*) as frequency 
FROM health.user_logs 
GROUP BY id, 
log_date, 
measure, 
measure_value,
systolic, 
diastolic 
ORDER BY frequency DESC;
– This code will count each record/row and how often they occur. Those with a count greater than one have duplicates.

A common table expression can also be used to identify values these duplicates.
WITH groupby_counts AS 
( SELECT
id, 
log_date, 
measure, 
measure_value, 
systolic,
diastolic, 
COUNT(*) AS frequency 
FROM health.user_logs 
GROUP BY
id, 
log_date, 
measure, 
measure_value, 
systolic,
diastolic 
) SELECT 
* 
FROM groupby_counts
WHERE frequency > 1 
ORDER BY frequency 
DESC LIMIT 10;

Practice Questions
1. Which id value has the most number of duplicate records in the health.user_logs table?

WITH cleaned_data as
( SELECT 
COUNT(*) as frequency 
FROM health.user_logs 
GROUP BY 
id, 
log_date, 
measure, 
measure_value, 
systolic,
diastolic
) SELECT
id,
sum(frequency) as total_duplicate_rows 
FROM cleaned_data 
WHERE frequency > 1 
GROUP BY id 
ORDER BY total_duplicate_rows DESC 
LIMIT 10;

2. Which log_date value had the most duplicate records after removing the max duplicate id value from question 1?

WITH cleaned_data as (
SELECT 
COUNT(*) as frequency 
FROM health.user_logs 
WHERE id != '054250c692e07a9fa9e62e345231df4b54ff435d' 
GROUP BY id, log_date, measure, measure_value, systolic, diastolic ) 
SELECT 
log_date, 
sum(frequency) as total_duplicate_rows 
FROM cleaned_data 
WHERE frequency > 1 group by 1 
ORDER BY total_duplicate_rows DESC 
LIMIT 10;

3. Which measure_value had the most occurrences in the health.user_logs value when measure = 'weight'?

SELECT 
measure_value, 
count(*) as frequency from health.user_logs 
WHERE measure = 'weight' 
GROUP BY 1 
ORDER BY frequency DESC 
LIMIT 1;

4. How many single duplicated rows exist when measure = 'blood_pressure' in the health.user_logs? How about the total number of duplicate records in the same table?

WITH row_counts as (
SELECT
id, 
log_date, 
measure, 
measure_value, 
systolic,
diastolic,
COUNT(*) as frequency
FROM health.user_logs 
WHERE measure = 'blood_pressure' 
GROUP BY id, 
log_date, 
measure, 
measure_value, 
systolic,
diastolic
) SELECT 
COUNT(*) as single_rows, 
SUM(frequency) as total_duplicate_rows 
FROM row_counts 
WHERE frequency > 1;

5.What percentage of records measure_value = 0 when measure = 'blood_pressure' in the health.user_logs table? How many records are there also for this same condition?

WITH all_measure_values as ( 
SELECT 
measure_value, 
COUNT(*) as total,
SUM(COUNT(*)) OVER() as overall_total 
FROM health.user_logs 
WHERE measure = 'blood_pressure' 
GROUP BY measure_value 
) SELECT 
measure_value,
total, 
overall_total, 
ROUND(100 * total / overall_total, 2) as percentage
FROM all_measure_values
WHERE measure_value = 0

6. What percentage of records are duplicates in the health.user_logs table?

WITH groupby_counts AS (
SELECT
id, 
log_date, 
measure, 
measure_value, 
systolic,
diastolic,
COUNT(*) AS frequency 
FROM health.user_logs 
GROUP BY
id, 
log_date, 
measure, 
measure_value, 
systolic,
diastolic 
) SELECT 
ROUND( 100 * SUM( CASE WHEN frequency > 1 THEN frequency - 1 ELSE 0 END ) :: NUMERIC / SUM(frequency), 2 ) AS duplicate_percentage 
FROM groupby_counts;
